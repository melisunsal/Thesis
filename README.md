# Thesis – Explainability in Predictive Process Mining

This repository contains the implementation for my Master’s thesis on **explainability of Transformer-based predictive process mining models**.  
The focus is on **next activity prediction** and **comparison of attention-based explanations with Shapley-based (deletion-only) explanations**.

---

## Project Goals

- Train a **ProcessTransformer** for next activity prediction
- Extract and visualize **multi-head self-attention**
- Compute **Shapley values using deletion-only perturbations**
- Compare explanation methods in terms of faithfulness and stability

---
## Reproducibility

All experiments were executed in a Python virtual environment.
Exact package versions are provided in `requirements.txt`.


